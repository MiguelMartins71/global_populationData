# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

import sys

sys.path.append("/Workspace/Users/miguelhmc9@gmail.com/global_populationData/notebooks/New Pipeline 2025-10-14 11:35")

# COMMAND ----------

df_global = spark.read.table("workspace.default.global_population_stats")
display(df_global)

# COMMAND ----------

print("\ESTAT√çSTICAS DESCRITIVAS:")
df_global.describe().show()

numeric_cols = [col_name for col_name, col_type in df_global.dtypes 
               if col_type in ['int', 'bigint', 'float', 'double', 'long']]

print(f"\nüî¢ Colunas num√©ricas encontradas: {numeric_cols}")
if numeric_cols:
    print("\nüìà Estat√≠sticas das colunas num√©ricas:")
    df_global.select(numeric_cols).describe().show()

# COMMAND ----------

print(f"Total de registros: {df_global.count():,}")
print(f"Total de colunas: {len(df_global.columns)}")
print(f"Colunas: {', '.join(df_global.columns)}")
print(f"Tipos de dados: {', '.join([f'{col}: {df_global.schema[col].dataType}' for col in df_global.columns])}")

# COMMAND ----------


from pyspark.sql import functions as f
total_pop = df_global.agg(f.sum("Population(in millions)")).first()[0]

df_global = df_global.withColumn(
    "Percent_of_world",
    f.round((f.col("Population(in millions)") / total_pop) * 100, 2)
)

display(
    df_global.orderBy("Percent_of_world", ascending=False).limit(10)
)



# COMMAND ----------


